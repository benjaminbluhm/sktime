{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow \n",
    "\n",
    "The sktime custom model flavor enables logging of sktime models in MLflow format via the `sktime.utils.mlflow_sktime.save_model()` and `sktime.utils.mlflow_sktime.log_model()` methods. These methods also add the `pyfunc` flavor to the MLflow Models that they produce, allowing the model to be interpreted as generic Python functions for inference via `sktime.utils.mlflow_sktime.pyfunc.load_model()`. This loaded PyFunc model can only be scored with a DataFrame input. You can also use the `sktime.utils.mlflow_sktime.load_model()` method to load MLflow Models with the sktime model flavor in native sktime formats.\n",
    "\n",
    "The `pyfunc` flavor of the model supports sktime predict methods `predict`,  `predict_interval`, `predict_quantiles` and `predict_var`.\n",
    "\n",
    "The interface for utilizing a sktime model loaded as a `pyfunc` type for generating forecasts requires passing an exogenous regressor as Pandas DataFrame to the `pyfunc.predict()` method (an empty DataFrame can be passed if no exogenous regressor is used). The configuration of predict methods and parameter values passed to the predict methods is defined by a dictionary to be saved as an attribute of the fitted sktime model instance (see code example below). \n",
    "\n",
    "Signature logging for sktime from a non-pyfunc artifact will not function correctly for `predict_interval` or `predict_quantiles`. The output of the native sktime model flavor for these methods is not a recognized signature type due to the MultiIndex column structure of the returned DataFrame. MLflow's ``infer_schema`` will function correctly if using the ``pyfunc`` flavor of the model, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "### 1.1 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.utils import mlflow_sktime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = load_longley()\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example usage of native `sktime flavor` and `pyfunc flavor`\n",
    "\n",
    "### 2.1 Create prediction config for pyfunc flavor\n",
    "- Pyfunc prediction config can be defined in two ways:\n",
    "    - `Dict[str, dict]` if parameter values are be passed to the arguments of predict method, for example  `{\"predict_method\": {\"predict\": None, \"predict_interval\": {\"coverage\": [0.1, 0.9]}}`\n",
    "    - `Dict[str, list]`, if using default parameters in predict method, for example  `{\"predict_method\": [\"predict\", \"predict_interval\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfunc_predict_conf = {\n",
    "    \"predict_method\": {\n",
    "        \"predict\": None,\n",
    "        \"predict_interval\": {\"coverage\": [0.1, 0.9]},\n",
    "        \"predict_quantiles\": {\"alpha\": [0.1, 0.9]},\n",
    "        \"predict_var\": {\"cov\": False},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    forecaster = NaiveForecaster()\n",
    "    forecaster.fit(\n",
    "        y_train,\n",
    "        X=X_train,\n",
    "        fh=[1, 2, 3],\n",
    "    )\n",
    "    forecaster.pyfunc_predict_conf = pyfunc_predict_conf\n",
    "\n",
    "    mlflow_sktime.save_model(forecaster, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load model\n",
    "\n",
    "#### 2.3.1 Native sktime flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow_sktime.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Pyfunc flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find sktime flavor configuration during model loading process. Assuming 'pickle' serialization format.\n"
     ]
    }
   ],
   "source": [
    "loaded_pyfunc = mlflow_sktime.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Generate predictions\n",
    "\n",
    "#### 2.4.1 Native sktime flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959    66513.0\n",
      "1960    66513.0\n",
      "1961    66513.0\n",
      "Freq: A-DEC, dtype: float64\n",
      "\n",
      "           Coverage              \n",
      "               0.9              \n",
      "             lower         upper\n",
      "1959  64211.598663  68814.401337\n",
      "1960  63258.327017  69767.672983\n",
      "1961  62526.855956  70499.144044\n",
      "\n",
      "          Quantiles              \n",
      "              0.05          0.95\n",
      "1959  64211.598663  68814.401337\n",
      "1960  63258.327017  69767.672983\n",
      "1961  62526.855956  70499.144044\n",
      "\n",
      "                  0\n",
      "1959  1.957628e+06\n",
      "1960  3.915256e+06\n",
      "1961  5.872885e+06\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.predict(X=X_test))\n",
    "print(\"\\n\", loaded_model.predict_interval(X=X_test))\n",
    "print(\"\\n\", loaded_model.predict_quantiles(X=X_test))\n",
    "print(\"\\n\", loaded_model.predict_var(X=X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Pyfunc flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict__0</th>\n",
       "      <th>predict_interval__Coverage__0.1__lower</th>\n",
       "      <th>predict_interval__Coverage__0.1__upper</th>\n",
       "      <th>predict_interval__Coverage__0.9__lower</th>\n",
       "      <th>predict_interval__Coverage__0.9__upper</th>\n",
       "      <th>predict_quantiles__Quantiles__0.1</th>\n",
       "      <th>predict_quantiles__Quantiles__0.9</th>\n",
       "      <th>predict_var__0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>66513.0</td>\n",
       "      <td>66337.180592</td>\n",
       "      <td>66688.819408</td>\n",
       "      <td>64211.598663</td>\n",
       "      <td>68814.401337</td>\n",
       "      <td>64719.913711</td>\n",
       "      <td>68306.086289</td>\n",
       "      <td>1.957628e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>66513.0</td>\n",
       "      <td>66264.353808</td>\n",
       "      <td>66761.646192</td>\n",
       "      <td>63258.327017</td>\n",
       "      <td>69767.672983</td>\n",
       "      <td>63977.193051</td>\n",
       "      <td>69048.806949</td>\n",
       "      <td>3.915256e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>66513.0</td>\n",
       "      <td>66208.471852</td>\n",
       "      <td>66817.528148</td>\n",
       "      <td>62526.855956</td>\n",
       "      <td>70499.144044</td>\n",
       "      <td>63407.283445</td>\n",
       "      <td>69618.716555</td>\n",
       "      <td>5.872885e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predict__0  predict_interval__Coverage__0.1__lower  \\\n",
       "1959     66513.0                            66337.180592   \n",
       "1960     66513.0                            66264.353808   \n",
       "1961     66513.0                            66208.471852   \n",
       "\n",
       "      predict_interval__Coverage__0.1__upper  \\\n",
       "1959                            66688.819408   \n",
       "1960                            66761.646192   \n",
       "1961                            66817.528148   \n",
       "\n",
       "      predict_interval__Coverage__0.9__lower  \\\n",
       "1959                            64211.598663   \n",
       "1960                            63258.327017   \n",
       "1961                            62526.855956   \n",
       "\n",
       "      predict_interval__Coverage__0.9__upper  \\\n",
       "1959                            68814.401337   \n",
       "1960                            69767.672983   \n",
       "1961                            70499.144044   \n",
       "\n",
       "      predict_quantiles__Quantiles__0.1  predict_quantiles__Quantiles__0.9  \\\n",
       "1959                       64719.913711                       68306.086289   \n",
       "1960                       63977.193051                       69048.806949   \n",
       "1961                       63407.283445                       69618.716555   \n",
       "\n",
       "      predict_var__0  \n",
       "1959    1.957628e+06  \n",
       "1960    3.915256e+06  \n",
       "1961    5.872885e+06  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pyfunc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model deployment example\n",
    "\n",
    "### 3.1 Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow run id: 1fe2a80b9842443aa4041a447a21d734\n"
     ]
    }
   ],
   "source": [
    "artifact_path = \"model\"\n",
    "\n",
    "mlflow.set_experiment(\"Test Sktime\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    forecaster = NaiveForecaster()\n",
    "    forecaster.fit(y_train, X=X_train, fh=[1, 2, 3])\n",
    "    forecaster.pyfunc_predict_conf = pyfunc_predict_conf\n",
    "\n",
    "    mlflow_sktime.log_model(sktime_model=forecaster, artifact_path=artifact_path)\n",
    "\n",
    "run_id = run.info.run_id\n",
    "print(f\"MLflow run id: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deploy pyfunc model to local REST API endpoint\n",
    "- Open a terminal window and cd into `examples`directory\n",
    "- In the terminal run: `mlflow models serve -m runs:/<RUN_ID>/model --env-manager local --host <HOST>`\n",
    "    - where you substitute `<RUN_ID>` by the `run_id` and `<HOST>` by the network address to listen on (e.g. `127.0.0.1`) \n",
    "- More details here: https://www.mlflow.org/docs/latest/cli.html#mlflow-models-serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Request predictions from local REST API endpoint\n",
    "\n",
    "- For mor details see: https://www.mlflow.org/docs/latest/models.html#built-in-deployment-tools\n",
    "\n",
    "#### 3.3.1 JSON input using `dataframe_split` field with pandas DataFrame in the `split` orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataframe_split': {'index': [0, 1, 2, 3], 'columns': ['GNPDEFL', 'GNP', 'UNEMP', 'ARMED', 'POP'], 'data': [[112.6, 482704.0, 3813.0, 2552.0, 123366.0], [114.2, 502601.0, 3931.0, 2514.0, 125368.0], [115.7, 518173.0, 4806.0, 2572.0, 127852.0], [116.9, 554894.0, 4007.0, 2827.0, 130081.0]]}}\n"
     ]
    }
   ],
   "source": [
    "host = \"127.0.0.1\"\n",
    "url = f\"http://{host}:5000/invocations\"\n",
    "\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "json_data = {\"dataframe_split\": X_test.to_dict(orient=\"split\")}\n",
    "print(json_data)\n",
    "\n",
    "# # Comment in the below lines to run the prediction request\n",
    "# import requests\n",
    "# response = requests.post(url, json=json_data)\n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 JSON input using `dataframe_records` field with pandas DataFrame in the `records` orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataframe_records': [{'GNPDEFL': 112.6, 'GNP': 482704.0, 'UNEMP': 3813.0, 'ARMED': 2552.0, 'POP': 123366.0}, {'GNPDEFL': 114.2, 'GNP': 502601.0, 'UNEMP': 3931.0, 'ARMED': 2514.0, 'POP': 125368.0}, {'GNPDEFL': 115.7, 'GNP': 518173.0, 'UNEMP': 4806.0, 'ARMED': 2572.0, 'POP': 127852.0}, {'GNPDEFL': 116.9, 'GNP': 554894.0, 'UNEMP': 4007.0, 'ARMED': 2827.0, 'POP': 130081.0}]}\n"
     ]
    }
   ],
   "source": [
    "json_data = {\"dataframe_records\": X_test.to_dict(orient=\"records\")}\n",
    "print(json_data)\n",
    "\n",
    "# # Comment in the below lines to run the prediction request\n",
    "# response = requests.post(url, json=json_data)\n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 CSV input using valid `pd.DataFrame` csv representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",GNPDEFL,GNP,UNEMP,ARMED,POP\n",
      "0,112.6,482704.0,3813.0,2552.0,123366.0\n",
      "1,114.2,502601.0,3931.0,2514.0,125368.0\n",
      "2,115.7,518173.0,4806.0,2572.0,127852.0\n",
      "3,116.9,554894.0,4007.0,2827.0,130081.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"text/csv\",\n",
    "}\n",
    "data = X_test.to_csv()\n",
    "print(data)\n",
    "\n",
    "# # Comment in the below lines to run the prediction request\n",
    "# response = requests.post(url, headers=headers, data=data)\n",
    "# response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
